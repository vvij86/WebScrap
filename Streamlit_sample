import openai
import streamlit as st

# Initialize the OpenAI API client
openai.api_type = "azure"
openai.api_base = "https://YOUR_AZURE_OPENAI_ENDPOINT"
openai.api_version = "2023-05-15"
openai.api_key = "YOUR_API_KEY"

# Define your prompt
prompt = "Explain the benefits of using Azure OpenAI's o3-mini model."

# Create a chat completion request with streaming enabled
response = openai.ChatCompletion.create(
    engine="o3-mini",
    messages=[
        {"role": "system", "content": "You are an AI assistant."},
        {"role": "user", "content": prompt},
    ],
    stream=True
)

# Initialize a variable to collect the response
collected_response = ""

# Define a generator function to stream the response
def stream_response():
    global collected_response
    for chunk in response:
        if 'choices' in chunk:
            chunk_message = chunk['choices'][0]['delta'].get('content', '')
            if chunk_message:
                collected_response += chunk_message
                yield chunk_message

# Display the streamed response in the Streamlit app
st.write_stream(stream_response())

# After streaming is complete, save the collected response to a Markdown file
with open("response.md", "w", encoding="utf-8") as md_file:
    md_file.write(collected_response)
